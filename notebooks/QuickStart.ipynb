{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "[Install the T4 Python client](https://github.com/quiltdata/t4/blob/master/UserDocs.md), `helium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the bucket you will run this demo against. This must be \n",
    "# an S3 bucket you have access to.\n",
    "bucket_name   = \"alpha-quilt-storage\"\n",
    "\n",
    "# The subfolder inside of the bucket that this demo will be placed in.\n",
    "bucket_folder = \"hurdat-demo\"\n",
    "\n",
    "# The local folder that will act as scratch space for some files we\n",
    "# will create in this notebook.\n",
    "# This path must end in a forward slash (\"/\").\n",
    "local_folder  = \"./\"\n",
    "\n",
    "# A date timestamp that will be included in the output path for files\n",
    "# pushed to S3 by this notebook. Helps ensure tidyness.\n",
    "from datetime import datetime\n",
    "bucket_subfolder = str(datetime.now())\\\n",
    "    .replace(\" \", \"-\").replace(\":\", \"_\").replace(\".\", \"_\")\n",
    "\n",
    "# Resulting path.\n",
    "t4_path = f'{bucket_name}/{bucket_folder}/{bucket_subfolder}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "This notebook offers a five-minute tour of the T4 Python API, codename `helium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniconda3/envs/quilt-dev/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import helium as he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4 lets you read and write data from S3. Every file in T4 is searchable, versioned, and secured according to your S3 policies.\n",
    "\n",
    "\n",
    "![](./helium-api.png)\n",
    "\n",
    "\n",
    "To start off, we'll need some data. Here's a script we've built that downloads and cleans up an NOAA hurricane dataset known as HURDAT. It is pretty typical of the sorts of clean-up scripts you'd be running when performing data science:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load hurdat/build.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates a history of Atlantic hurricanes in a `pandas` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>record_identifier</th>\n",
       "      <th>status_of_system</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>maximum_sustained_wind_knots</th>\n",
       "      <th>maximum_pressure</th>\n",
       "      <th>34_kt_ne</th>\n",
       "      <th>...</th>\n",
       "      <th>34_kt_sw</th>\n",
       "      <th>34_kt_nw</th>\n",
       "      <th>50_kt_ne</th>\n",
       "      <th>50_kt_se</th>\n",
       "      <th>50_kt_sw</th>\n",
       "      <th>50_kt_nw</th>\n",
       "      <th>64_kt_ne</th>\n",
       "      <th>64_kt_se</th>\n",
       "      <th>64_kt_sw</th>\n",
       "      <th>64_kt_nw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 21:00:00</td>\n",
       "      <td>L</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     name                date record_identifier  \\\n",
       "index                                                            \n",
       "0      AL011851  UNNAMED 1851-06-25 00:00:00               NaN   \n",
       "1      AL011851  UNNAMED 1851-06-25 06:00:00               NaN   \n",
       "2      AL011851  UNNAMED 1851-06-25 12:00:00               NaN   \n",
       "3      AL011851  UNNAMED 1851-06-25 18:00:00               NaN   \n",
       "4      AL011851  UNNAMED 1851-06-25 21:00:00                 L   \n",
       "\n",
       "      status_of_system latitude longitude maximum_sustained_wind_knots  \\\n",
       "index                                                                    \n",
       "0                   HU     28.0     -94.8                           80   \n",
       "1                   HU     28.0     -95.4                           80   \n",
       "2                   HU     28.0     -96.0                           80   \n",
       "3                   HU     28.1     -96.5                           80   \n",
       "4                   HU     28.2     -96.8                           80   \n",
       "\n",
       "      maximum_pressure 34_kt_ne   ...    34_kt_sw 34_kt_nw 50_kt_ne 50_kt_se  \\\n",
       "index                             ...                                          \n",
       "0                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "1                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "2                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "3                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "4                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "\n",
       "      50_kt_sw 50_kt_nw 64_kt_ne 64_kt_se 64_kt_sw 64_kt_nw  \n",
       "index                                                        \n",
       "0          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlantic_storms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and write objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`helium` lets you read and write Python objects with `put()`. `put()` accepts an optional `metadata=` keyword. Use `metadata=` to annotate objects. T4 indexes all metadata so that you can find specific objects or files with `search()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.put(atlantic_storms, t4_path + \"atlantic-storms-data.parquet\",\n",
    "       meta={'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt', \n",
    "             'ocean': 'atlantic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve them (along with the metadata) using `get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storms, meta = he.get(t4_path + \"atlantic-storms-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt',\n",
       " 'ocean': 'atlantic'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`put` transparently chooses file formats for common data structures. In the above example , that meant writing a `pandas.DataFrame` as a `.parquet` file.\n",
    "\n",
    "To move files to S3, use `put_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filepath = f\"{local_folder}atlantic-storms.csv\"\n",
    "atlantic_storms.to_csv(local_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./atlantic-storms.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls $local_filepath | grep 'atlantic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148096cdfcba4990a718c7cf093840b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3871481), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "he.put_file(local_filepath, t4_path + \"atlantic-storms-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object versions\n",
    "\n",
    "It is recommended that you use T4 on an S3 bucket with [object versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html) enabled.\n",
    "\n",
    "Every time you write to a versioned S3 bucket, including with `he.put*`, a new *object version* is born. With an object version, you can reconstruct the contents of an object at any point in time.\n",
    "\n",
    "You can list object version with `ls` command. For example, here are the first three versions of some files in our HURDAT project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ETag': '\"701df1515152860cf2a7a8498133ca82\"',\n",
       "  'Size': 3871481,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': 'hurdat-demo/2018-10-11-13_22_16_617100/atlantic-storms-data.csv',\n",
       "  'VersionId': 's9.iEupWjhaaT7lg1JcRNqK_D3ms8R3M',\n",
       "  'IsLatest': True,\n",
       "  'LastModified': datetime.datetime(2018, 10, 11, 20, 22, 54, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'}},\n",
       " {'ETag': '\"502f21cfc143fb0c35f563eda5699fa9\"',\n",
       "  'Size': 923078,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': 'hurdat-demo/2018-10-11-13_22_16_617100/atlantic-storms-data.parquet',\n",
       "  'VersionId': 'IY3CMAr6G7TtEoG30kR2QHsvEyxz.HjK',\n",
       "  'IsLatest': True,\n",
       "  'LastModified': datetime.datetime(2018, 10, 11, 20, 22, 37, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.ls(t4_path)[1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, T4 will offer other ways of accessing version information more directly.\n",
    "\n",
    "To grab a specific object version, use the optional `version=` keyword to `get()` or `get_file()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and specify the version from the output above.\n",
    "data, meta = he.get(t4_path + \"atlantic-storms-data.parquet\", \n",
    "                    version=\"IY3CMAr6G7TtEoG30kR2QHsvEyxz.HjK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You'll need to provide the full object version for this to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot folders in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- In the future this section should treat versions, not snapshots. -->\n",
    "\n",
    "A T4 **snapshot** is an immutable picture of one or more objects in S3 at a specific moment in time. Whereas object versions are for single objects, snapshots are for one or more objects.\n",
    "\n",
    "The snapshot `path` means \"seal everything underneath this key\" in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17b3c6dea9937dfef9123ef371d927bb3939b6493d49f15ecbdbe3512ac35e40'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.snapshot(t4_path, message=\"Initial snapshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list snapshots of an S3 key using `list_snapshots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hurdat-demo/2018-10-11-13_22_16_617100/</th>\n",
       "      <td>17b3c6dea9937dfef9123ef371d927bb3939b6493d49f1...</td>\n",
       "      <td>2018-10-11 20:24:00+00:00</td>\n",
       "      <td>Initial snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af...</td>\n",
       "      <td>2018-10-08 22:26:29+00:00</td>\n",
       "      <td>foo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>435d7b954fe6dbd35cf51b311971fc49643d24af9f6f69...</td>\n",
       "      <td>2018-10-08 21:21:01+00:00</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'hash': '17b3c6dea9937dfef9123ef371d927bb3939b6493d49f15ecbdbe3512ac35e40',\n",
       "  'path': 'hurdat-demo/2018-10-11-13_22_16_617100/',\n",
       "  'message': 'Initial snapshot',\n",
       "  'timestamp': datetime.datetime(2018, 10, 11, 20, 24, tzinfo=tzutc())},\n",
       " {'hash': 'ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af7af7f865d6d7177e98',\n",
       "  'path': '',\n",
       "  'message': 'foo2',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 22, 26, 29, tzinfo=tzutc())},\n",
       " {'hash': '435d7b954fe6dbd35cf51b311971fc49643d24af9f6f698544f87d7e24ebe83c',\n",
       "  'path': '',\n",
       "  'message': 'foo',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 21, 21, 1, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.list_snapshots(\n",
    "    bucket_name, \n",
    "\n",
    "    # e.g. 'hurdat-demo/2018-10-11-11_53_37_098339/'\n",
    "    contains=f'{bucket_folder}/{bucket_subfolder}/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can diff overlapping snapshots to see what's changed. In this case `\"latest\"` represents what is currently in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.put({\"description\": \"A simple JSON file\"}, \n",
    "       t4_path + \"simple.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>ETag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Added</th>\n",
       "      <td>hurdat-demo/2018-10-11-13_22_16_617100/simple....</td>\n",
       "      <td>\"725f0cda0939ef902a1cb9bcb89923cd\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'Key': 'hurdat-demo/2018-10-11-13_22_16_617100/simple.json',\n",
       "  'ETag': '\"725f0cda0939ef902a1cb9bcb89923cd\"',\n",
       "  'status': 'Added'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and specify the snapshot from the output above.\n",
    "he.diff(bucket_name, \"17b3c6d\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshots can be used to version anything with an S3 key, but are at their most useful when versioning **data packages**: groups of files which together represent the data component to a specific project you are working on.\n",
    "\n",
    "You can think of a data project as having three components: code, environment, and data. Versioning code is obvious: just use `git`. Similarly, sophisticated tools exist for versioning environments: `conda` and Docker, for example.\n",
    "\n",
    "But what about your data? Data can balloon to many terabytes in size, becoming too large for `git` or Docker to manage. At the same time, in data science, small changes in data can often have disproportionate impact in your analysis and throw off your models. In a [seminal paper](https://ai.google/research/pubs/pub43146) on data systems, Google refered to this as the CACE principle: \"Changing Anything Changes Everything\". \n",
    "\n",
    "Clearly, data needs its own native versioning tool. T4 snapshots provide just that!\n",
    "\n",
    "To demonstrate, let's start by cloning a simple project using our storms data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'hurdat-example-repo'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 12 (delta 0), reused 12 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!cd $local_folder; git clone https://github.com/ResidentMario/hurdat-example-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project contains an `environment.yml` file defining our code environment, a `notebooks` folder containing some Jupyter notebooks, and a `data` folder containing inputs and outputs.\n",
    "\n",
    "Our objective: smartly manage our `data`. With T4 snapshots, this is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d62535aaf6f400eae7487f0bf5eca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3758670), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "he.put_file(\n",
    "    local_folder + \"hurdat-example-repo/data/\",\n",
    "    t4_path + \"data/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61cc385ebfdb5eba5f005605742ebba6cdda4034169809130e38ac73c7da5de3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.snapshot(t4_path + \"data/\", message=\"Snap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hurdat-demo/2018-10-11-13_22_16_617100/data/</th>\n",
       "      <td>61cc385ebfdb5eba5f005605742ebba6cdda4034169809...</td>\n",
       "      <td>2018-10-11 20:24:35+00:00</td>\n",
       "      <td>Snap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurdat-demo/2018-10-11-13_22_16_617100/</th>\n",
       "      <td>17b3c6dea9937dfef9123ef371d927bb3939b6493d49f1...</td>\n",
       "      <td>2018-10-11 20:24:00+00:00</td>\n",
       "      <td>Initial snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af...</td>\n",
       "      <td>2018-10-08 22:26:29+00:00</td>\n",
       "      <td>foo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>435d7b954fe6dbd35cf51b311971fc49643d24af9f6f69...</td>\n",
       "      <td>2018-10-08 21:21:01+00:00</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'hash': '61cc385ebfdb5eba5f005605742ebba6cdda4034169809130e38ac73c7da5de3',\n",
       "  'path': 'hurdat-demo/2018-10-11-13_22_16_617100/data/',\n",
       "  'message': 'Snap.',\n",
       "  'timestamp': datetime.datetime(2018, 10, 11, 20, 24, 35, tzinfo=tzutc())},\n",
       " {'hash': '17b3c6dea9937dfef9123ef371d927bb3939b6493d49f15ecbdbe3512ac35e40',\n",
       "  'path': 'hurdat-demo/2018-10-11-13_22_16_617100/',\n",
       "  'message': 'Initial snapshot',\n",
       "  'timestamp': datetime.datetime(2018, 10, 11, 20, 24, tzinfo=tzutc())},\n",
       " {'hash': 'ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af7af7f865d6d7177e98',\n",
       "  'path': '',\n",
       "  'message': 'foo2',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 22, 26, 29, tzinfo=tzutc())},\n",
       " {'hash': '435d7b954fe6dbd35cf51b311971fc49643d24af9f6f698544f87d7e24ebe83c',\n",
       "  'path': '',\n",
       "  'message': 'foo',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 21, 21, 1, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.list_snapshots(bucket_name, \n",
    "                  contains=f'{bucket_folder}/{bucket_subfolder}/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenever we want to grab a file from a particular snapshot of this particular data project, we need only pass its hash to the `snapshot` parameter of `get_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6968d04415dd469991d637d3928aacdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3758670), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "he.get_file(t4_path + \"data/atlantic.csv\", \n",
    "            local_folder + \"atlantic.csv\",\n",
    "            snapshot=\"61cc38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this hash into your `README.md` and enjoy your newfound project reproducibility!\n",
    "\n",
    "In summary, every data science product&mdash;be it an analysis, a model, or exposition&mdash;relies on a new collection of data file **versions**, which a data science can logically organize into one (or more) **snapshots**. These snapshots are **immutable**, and, in conjunction with version control on the project code and the project environment, enable reproducible, distributable data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum&mdash;clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_repo      = local_folder + \"hurdat-example-repo\"\n",
    "local_data_copy = local_folder + \"atlantic-storms.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $local_repo\n",
    "!rm $local_data_copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
