{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "[Install the T4 Python client](https://github.com/quiltdata/t4/blob/master/UserDocs.md), `helium`.\n",
    "\n",
    "## Intro\n",
    "This notebook offers a five-minute tour of the T4 Python API, codename `helium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karve/anaconda3/envs/dev/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/Users/karve/anaconda3/envs/dev/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import helium as he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4 lets you read and write data from S3. Every file in T4 is searchable, versioned, and secured according to your S3 policies.\n",
    "\n",
    "\n",
    "![](./helium-api.png)\n",
    "\n",
    "\n",
    "To start off, we'll need some data. Here's a script we've built that downloads and cleans up an NOAA hurricane dataset known as HURDAT. It is pretty typical of the sorts of clean-up scripts you'd be running when performing data science:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load hurdat/build.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates a history of Atlantic hurricanes in a `pandas` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>record_identifier</th>\n",
       "      <th>status_of_system</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>maximum_sustained_wind_knots</th>\n",
       "      <th>maximum_pressure</th>\n",
       "      <th>34_kt_ne</th>\n",
       "      <th>...</th>\n",
       "      <th>34_kt_sw</th>\n",
       "      <th>34_kt_nw</th>\n",
       "      <th>50_kt_ne</th>\n",
       "      <th>50_kt_se</th>\n",
       "      <th>50_kt_sw</th>\n",
       "      <th>50_kt_nw</th>\n",
       "      <th>64_kt_ne</th>\n",
       "      <th>64_kt_se</th>\n",
       "      <th>64_kt_sw</th>\n",
       "      <th>64_kt_nw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 21:00:00</td>\n",
       "      <td>L</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     name                date record_identifier  \\\n",
       "index                                                            \n",
       "0      AL011851  UNNAMED 1851-06-25 00:00:00               NaN   \n",
       "1      AL011851  UNNAMED 1851-06-25 06:00:00               NaN   \n",
       "2      AL011851  UNNAMED 1851-06-25 12:00:00               NaN   \n",
       "3      AL011851  UNNAMED 1851-06-25 18:00:00               NaN   \n",
       "4      AL011851  UNNAMED 1851-06-25 21:00:00                 L   \n",
       "\n",
       "      status_of_system latitude longitude maximum_sustained_wind_knots  \\\n",
       "index                                                                    \n",
       "0                   HU     28.0     -94.8                           80   \n",
       "1                   HU     28.0     -95.4                           80   \n",
       "2                   HU     28.0     -96.0                           80   \n",
       "3                   HU     28.1     -96.5                           80   \n",
       "4                   HU     28.2     -96.8                           80   \n",
       "\n",
       "      maximum_pressure 34_kt_ne   ...    34_kt_sw 34_kt_nw 50_kt_ne 50_kt_se  \\\n",
       "index                             ...                                          \n",
       "0                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "1                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "2                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "3                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "4                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "\n",
       "      50_kt_sw 50_kt_nw 64_kt_ne 64_kt_se 64_kt_sw 64_kt_nw  \n",
       "index                                                        \n",
       "0          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlantic_storms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and write objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`helium` lets you read and write Python objects with `put()`. `put()` accepts an optional `metadata=` keyword. Use `metadata=` to annotate objects. T4 indexes all metadata so that you can find specific objects or files with `search()`.\n",
    "\n",
    "In the example below are are working with an S3 bucket called `alpha-quilt-storage`. To write to your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.put(atlantic_storms, \"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.parquet\",\n",
    "       meta={'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt', \n",
    "             'ocean': 'atlantic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve them (along with the metadata) using `get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storms, meta = he.get(\"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocean': 'atlantic',\n",
       " 'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`put` transparently chooses file formats for common data structures. In the above example , that meant writing a `pandas.DataFrame` as a `.parquet` file.\n",
    "\n",
    "To move files to S3, use `put_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"~/Desktop/atlantic-storms.csv\"\n",
    "atlantic_storms.to_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlantic-storms.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls ~/Desktop | grep 'atlantic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e307472d744bdfba46ccdd9afbf8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3871481), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "he.put_file(\"/Users/alex/Desktop/atlantic-storms.csv\", \"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object versions\n",
    "\n",
    "It is recommended that you use T4 on an S3 bucket with [object versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html) enabled.\n",
    "\n",
    "Every time you write to a versioned S3 bucket, including with `he.put*`, a new *object version* is born. With an object version, you can reconstruct the contents of an object at any point in time.\n",
    "\n",
    "You can list object version with `ls` command. For example, here are the first three versions of some files in our HURDAT project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'IsLatest': False,\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 13, 14, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'},\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'VersionId': 'jwSyCWiv_zL5Lg.sOyN1RMMQCnGzk.0O'},\n",
       " {'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'IsLatest': False,\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 11, 41, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'},\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'VersionId': 'HvmCd4AGwG4Og3mwGxQMfPDWiZhmtII3'},\n",
       " {'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'IsLatest': False,\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 9, 53, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'},\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'VersionId': 'iUxtMYQh.Z3mInIaitovWpdEP3XY9DKb'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.ls(\"alpha-quilt-storage/~aleksey/hurdat\")[1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, T4 sill offer other ways of accessing version information more directly.\n",
    "\n",
    "To grab a specific object version ,use the optional `version=` keyword to `get()` or `get_file()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = he.get(\"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms.parquet\", \n",
    "                    version=\"mP4USSZF2mJSaKNvr7EjUldDQm3Sqb_b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You'll need to provide the full object version for this to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot folders in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- In the future this section should treat versions, not snapshots. -->\n",
    "\n",
    "A T4 **snapshot** is an immutable picture of one or more objects in S3 at a specific moment in time. Whereas object versions are for single objects, snapshots are for one or more objects.\n",
    "\n",
    "The snapshot `path` means \"seal everything underneath this key\" in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'724cde9ad4688727ce886b5ece405103c3cb152d7ac076c88d2bf2cd254a1e66'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.snapshot(\"alpha-quilt-storage/~aleksey/hurdat/\", message=\"Third cut at cleaning up HURDAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list snapshots of an S3 key using `list_snapshots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>~aleksey/hurdat/</th>\n",
       "      <td>724cde9ad4688727ce886b5ece405103c3cb152d7ac076...</td>\n",
       "      <td>2018-10-09 23:09:19+00:00</td>\n",
       "      <td>Third cut at cleaning up HURDAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af...</td>\n",
       "      <td>2018-10-08 22:26:29+00:00</td>\n",
       "      <td>foo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~aleksey/</th>\n",
       "      <td>5460a76611597d3cf53ea4b0acb8d9695261523ac04de5...</td>\n",
       "      <td>2018-10-08 22:26:16+00:00</td>\n",
       "      <td>foo2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~aleksey/</th>\n",
       "      <td>9aa46097e10cb7b22a6667ac4bb7b6329b2411240936aa...</td>\n",
       "      <td>2018-10-08 22:01:13+00:00</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>435d7b954fe6dbd35cf51b311971fc49643d24af9f6f69...</td>\n",
       "      <td>2018-10-08 21:21:01+00:00</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~aleksey/hurdat/</th>\n",
       "      <td>7b1e211f91ac3242748c1423525f7d6e846914c055a6c5...</td>\n",
       "      <td>2018-10-05 00:36:20+00:00</td>\n",
       "      <td>Temporary message.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'hash': '724cde9ad4688727ce886b5ece405103c3cb152d7ac076c88d2bf2cd254a1e66',\n",
       "  'message': 'Third cut at cleaning up HURDAT',\n",
       "  'path': '~aleksey/hurdat/',\n",
       "  'timestamp': datetime.datetime(2018, 10, 9, 23, 9, 19, tzinfo=tzutc())},\n",
       " {'hash': 'ad9f3e3d938da7fbc5624245fbcb72f5bc25c2dfe4f9af7af7f865d6d7177e98',\n",
       "  'message': 'foo2',\n",
       "  'path': '',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 22, 26, 29, tzinfo=tzutc())},\n",
       " {'hash': '5460a76611597d3cf53ea4b0acb8d9695261523ac04de5859991fbe1c0adf24e',\n",
       "  'message': 'foo2',\n",
       "  'path': '~aleksey/',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 22, 26, 16, tzinfo=tzutc())},\n",
       " {'hash': '9aa46097e10cb7b22a6667ac4bb7b6329b2411240936aa7aee22123429807c14',\n",
       "  'message': 'foo',\n",
       "  'path': '~aleksey/',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 22, 1, 13, tzinfo=tzutc())},\n",
       " {'hash': '435d7b954fe6dbd35cf51b311971fc49643d24af9f6f698544f87d7e24ebe83c',\n",
       "  'message': 'foo',\n",
       "  'path': '',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 21, 21, 1, tzinfo=tzutc())},\n",
       " {'hash': '7b1e211f91ac3242748c1423525f7d6e846914c055a6c5b4c2d899fd9d0e1f2f',\n",
       "  'message': 'Temporary message.',\n",
       "  'path': '~aleksey/hurdat/',\n",
       "  'timestamp': datetime.datetime(2018, 10, 5, 0, 36, 20, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.list_snapshots(\"alpha-quilt-storage/~aleksey/hurdat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.put({\"description\": \"A simple JSON file\"}, \"alpha-quilt-storage/~aleksey/hurdat/simple.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can diff overlapping snapshots to see what's changed. In this case `\"latest\"` represents what is currently in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>ETag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Added</th>\n",
       "      <td>~aleksey/hurdat/simple.json</td>\n",
       "      <td>\"725f0cda0939ef902a1cb9bcb89923cd\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'ETag': '\"725f0cda0939ef902a1cb9bcb89923cd\"',\n",
       "  'Key': '~aleksey/hurdat/simple.json',\n",
       "  'status': 'Added'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.diff(\"alpha-quilt-storage\", \"724cde9ad46\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshots can be used to version anything with an S3 key, but are at their most useful when versioning **data packages**: groups of files which together represent the data component to a specific project you are working on.\n",
    "\n",
    "You can think of a data project as having three components: code, environment, and data. Versioning code is obvious: just use `git`. Similarly, sophisticated tools exist for versioning environments: `conda` and Docker, for example.\n",
    "\n",
    "But what about your data? Data can balloon to many terabytes in size, becoming too large for `git` or Docker to manage. At the same time, in data science, small changes in data can often have disproportionate impact in your analysis and throw off your models. In a [seminal paper](https://ai.google/research/pubs/pub43146) on data systems, Google refered to this as the CACE principle: \"Changing Anything Changes Everything\". \n",
    "\n",
    "Clearly, data needs its own native versioning tool. T4 snapshots provide just that!\n",
    "\n",
    "To demonstrate, let's start by cloning a simple project using our storms data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/Desktop; git clone https://github.com/ResidentMario/hurdat-example-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project contains an `environment.yml` file defining our code environment, a `notebooks` folder containing some Jupyter notebooks, and a `data` folder containing inputs and outputs.\n",
    "\n",
    "Our objective: smartly manage our `data`. With T4 snapshots, this is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: replace this path with one that works on your local machine.\n",
    "he.put_file(\"/Users/alex/Desktop/hurdat-example-repo/data/\", \n",
    "            \"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.snapshot(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\", message=\"Snap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.list_snapshots(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenever we want to grab a file from a particular snapshot of this particular data project, we need only pass its hash to the `snapshot` parameter of `get_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: replace this path with one that works on your local machine.\n",
    "he.get_file(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/atlantic.csv\", \n",
    "            \"/Users/alex/Desktop/hurdat-example-repo/data/atlantic.csv\",\n",
    "            snapshot=\"cb06134062b8b8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this hash into your `README.md` and enjoy your newfound project reproducibility!\n",
    "\n",
    "In summary, every data science product&mdash;be it an analysis, a model, or exposition&mdash;relies on a new collection of data file **versions**, which a data science can logically organize into one (or more) **snapshots**. These snapshots are **immutable**, and, in conjunction with version control on the project code and the project environment, enable reproducible, distributable data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum&mdash;clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!rm -rf ~/Desktop/hurdat-example-repo\n",
    "!rm ~/Desktop/atlantic-storms.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
